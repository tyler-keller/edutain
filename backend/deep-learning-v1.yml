title: deep-learning
description: MIT Press book on deep learning.
chapters:

  # chapter 1
  - chapter: 1
    questions:
      - question: What is deep learning?
        answer: Deep learning is an approach to artificial intelligence (AI) that uses a hierarchy of concepts, with each concept defined through its relation to simpler concepts. This allows computers to learn from experience and understand the world in a more intuitive way.
      - question: Why is deep learning becoming more popular now?
        answer: Deep learning has been around for decades, but recent advancements in computing power, larger datasets, and improved training algorithms have made it a more viable and powerful technology.
      - question: What are some of the historical trends in deep learning?
        answer: Deep learning has been known by different names throughout its history, such as cybernetics, connectionism, and artificial neural networks. It has gained popularity as the amount of available training data has increased and the size of deep learning models has grown due to advancements in computer infrastructure.
      - question: How does deep learning relate to the brain?
        answer: Deep learning is inspired by the brain, but it's not an attempt to simulate the brain.  The concept of having many interconnected units that learn through interaction is inspired by the brain, but deep learning mainly draws on applied math and statistics.
      - question: What is the significance of distributed representation in deep learning?
        answer: Distributed representation is the idea that each input to a system should be represented by many features, and each feature should be involved in the representation of many possible inputs. This allows for more efficient learning and generalization.
      - question: What are the different ways to measure the depth of a deep learning model?
        answer: Depth can be measured as the number of sequential instructions needed to evaluate the model or as the depth of the graph describing how concepts are related to each other.
      - question: How does deep learning enable the computer to learn complex concepts?
        answer: Deep learning allows computers to build complex concepts out of simpler ones by representing the world as a nested hierarchy of concepts.
      - question: What are the main challenges in deep learning?
        answer:  One of the main challenges is to disentangle factors of variation, meaning to separate the different sources of influence that affect the data. This is crucial for accurately interpreting and understanding the data.
      - question: What are some of the key applications of deep learning?
        answer: Deep learning has achieved great success in various fields, including computer vision, speech recognition, natural language processing, robotics, and scientific research.

  # chapter 2
  - chapter: 2
    questions:
      - question: What are scalars, vectors, matrices, and tensors?
        answer: Scalars are single numbers. Vectors are ordered arrays of numbers. Matrices are 2D arrays of numbers. Tensors are arrays of numbers with a variable number of axes.
      - question: What is the transpose of a matrix?
        answer: The transpose of a matrix is its mirror image across the main diagonal. It is denoted by A‚ä§.
      - question: How do you multiply matrices and vectors?
        answer: Matrix multiplication is not just element-wise multiplication. The result of multiplying a matrix A by a matrix B is a matrix C where each element Cij is the dot product of row i of A and column j of B.
      - question: What is the identity matrix?
        answer: The identity matrix is a square matrix that does not change any vector when multiplied by it. It is denoted by In.
      - question: What is the matrix inverse?
        answer: The inverse of a matrix A is denoted by A-1 and satisfies A-1A = I. It allows for solving systems of linear equations.
      - question: What is linear dependence and span?
        answer: A set of vectors is linearly dependent if one vector can be expressed as a linear combination of the others. The span of a set of vectors is the set of all points obtainable by linear combinations of those vectors.
      - question: What is a norm?
        answer: A norm is a function that measures the size of a vector. The L2 norm, also known as the Euclidean norm, measures the Euclidean distance from the origin to the point represented by the vector.
      - question: What are diagonal, symmetric, and orthogonal matrices?
        answer: A diagonal matrix has nonzero entries only along the main diagonal. A symmetric matrix is equal to its own transpose. An orthogonal matrix has orthonormal rows and columns.
      - question: What is eigendecomposition?
        answer: Eigendecomposition decomposes a matrix into eigenvectors and eigenvalues. An eigenvector is a nonzero vector that is only scaled by multiplication by the matrix, and the corresponding eigenvalue is the scaling factor.
      - question: What is singular value decomposition (SVD)?
        answer: SVD factorizes a matrix into singular vectors and singular values. It is applicable to all real matrices, unlike eigendecomposition.
      - question: What is the Moore-Penrose pseudoinverse?
        answer: The pseudoinverse generalizes matrix inversion to nonsquare matrices. It provides a solution to a linear equation with minimal Euclidean norm or finds the closest solution if none exists.
      - question: What is the trace operator?
        answer: The trace operator returns the sum of the diagonal entries of a matrix.
      - question: What is the determinant of a matrix?
        answer: The determinant is a function mapping square matrices to real scalars. It equals the product of all eigenvalues and represents how much multiplication by the matrix expands or contracts space.
      - question: What is principal components analysis (PCA)?
        answer: PCA is a dimensionality reduction technique that uses linear algebra to find a lower-dimensional representation of a dataset while minimizing information loss.

  # chapter 3
  - chapter: 3
    questions:
      - question: What is probability theory and why is it important for machine learning?
        answer: Probability theory is a mathematical framework for representing uncertain statements, allowing us to quantify uncertainty and derive new uncertain statements. It is essential for machine learning because it provides a means to reason in the presence of uncertain and stochastic quantities.
      - question: What are the three sources of uncertainty in machine learning?
        answer: Uncertainty can arise from inherent stochasticity in the system, incomplete observability, or incomplete modeling.
      - question: What is the difference between frequentist and Bayesian probability?
        answer: Frequentist probability deals with the frequency of events in repeated trials. Bayesian probability represents degrees of belief based on available evidence.
      - question: What is a random variable?
        answer: A random variable is a variable that can take on different values randomly. It is defined by its possible states and their associated probabilities.
      - question: What are probability mass functions (PMFs) and probability density functions (PDFs)?
        answer: PMFs describe probability distributions over discrete variables, mapping each state to its probability. PDFs describe probability distributions over continuous variables, where the probability of a state is given by the integral of the PDF over an infinitesimal region.
      - question: What is marginal probability?
        answer: Marginal probability is the probability distribution over a subset of variables given the joint probability distribution over all variables.
      - question: What is conditional probability?
        answer: Conditional probability is the probability of an event given that another event has occurred.
      - question: What is the chain rule of conditional probabilities?
        answer: The chain rule allows decomposing a joint probability distribution into a product of conditional distributions over single variables.
      - question: What is independence and conditional independence?
        answer: Independence means two random variables have a joint distribution that factorizes into products involving only each variable. Conditional independence means two variables are independent given a third variable.
      - question: What are expectation, variance, and covariance?
        answer: Expectation is the average value of a function of a random variable. Variance measures how much the values of a function vary. Covariance measures how much two variables are linearly related.
      - question: What are some common probability distributions used in machine learning?
        answer: Common distributions include Bernoulli, multinoulli, Gaussian, exponential, Laplace, and Dirac distributions.
      - question: What is the logistic sigmoid function and why is it useful?
        answer: The logistic sigmoid is a function that outputs values between 0 and 1, making it suitable for producing probabilities.
      - question: What is Bayes' rule and how is it used?
        answer: Bayes' rule allows calculating the conditional probability of one variable given another, given the conditional probability in the opposite direction and the marginal probability of the first variable.
      - question: What are structured probabilistic models?
        answer: Structured probabilistic models represent probability distributions over many variables using graphs, allowing for more efficient representation and computation.
      - question: What is the difference between directed and undirected graphical models?
        answer: Directed models represent factorizations into conditional probability distributions and use directed edges. Undirected models represent factorizations into functions and use undirected edges.
      - question: What is information theory and how is it used in machine learning?
        answer: Information theory quantifies the amount of information in a signal. It is used in machine learning to characterize probability distributions and measure similarity between them.
      - question: What is self-information, Shannon entropy, and KL divergence?
        answer: Self-information quantifies the information content of a single event. Shannon entropy measures the uncertainty of an entire probability distribution. KL divergence measures the difference between two probability distributions.
      - question: What is cross-entropy and how is it related to KL divergence?
        answer: Cross-entropy is similar to KL divergence but lacks the entropy term. Minimizing cross-entropy is equivalent to minimizing KL divergence.

  # chapter 4
  - chapter: 4
    questions:
      - question: What is numerical computation and why is it important for machine learning?
        answer: Numerical computation refers to algorithms that solve mathematical problems iteratively, by updating estimates of the solution. It is crucial for machine learning because many algorithms involve optimization and solving systems of equations, tasks that are often difficult to solve analytically.
      - question: What are overflow and underflow and how can they affect numerical computations?
        answer: Overflow occurs when numbers with large magnitudes are approximated as infinity. Underflow occurs when numbers near zero are rounded to zero. Both can lead to inaccurate results or errors in algorithms.
      - question: What is poor conditioning and how does it affect matrix inversion?
        answer: Poor conditioning means a function is very sensitive to small changes in its input. In the context of matrix inversion, a high condition number amplifies errors in the input, leading to inaccurate results.
      - question: What is gradient-based optimization and how does it work?
        answer: Gradient-based optimization uses the derivative of a function to iteratively find the minimum or maximum value by moving in the direction of the negative or positive gradient, respectively.
      - question: What are critical points, local minima, local maxima, and saddle points?
        answer: Critical points are points where the derivative of a function is zero. Local minima are points lower than their neighbors, local maxima are higher, and saddle points have neighbors that are both higher and lower.
      - question: What is gradient descent and how does it differ from the method of steepest descent?
        answer: Gradient descent is an algorithm that iteratively updates the input of a function by moving in the direction of the negative gradient. The method of steepest descent is a special case of gradient descent where the step size is chosen to maximize the decrease in the function.
      - question: What are Jacobian and Hessian matrices?
        answer: The Jacobian matrix contains all partial derivatives of a vector-valued function. The Hessian matrix contains all second partial derivatives of a scalar-valued function.
      - question: What is the second derivative test and how is it used to find critical points?
        answer: The second derivative test uses the second derivative to determine whether a critical point is a local minimum (positive second derivative), local maximum (negative second derivative), or inconclusive (zero second derivative).
      - question: What is Newton's method and how does it use the Hessian matrix?
        answer: Newton's method is a second-order optimization algorithm that uses the Hessian matrix to approximate the function as a quadratic near a point and jumps directly to the minimum of the approximation.
      - question: What is constrained optimization?
        answer: Constrained optimization involves finding the optimal value of a function subject to constraints on its input variables.
      - question: What is the Karush-Kuhn-Tucker (KKT) approach and how is it used for constrained optimization?
        answer: The KKT approach introduces a generalized Lagrangian function that incorporates constraints using Lagrange multipliers. By minimizing the Lagrangian, one can find the optimal solution that satisfies the constraints.
      - question: What are the KKT conditions and how are they used?
        answer: The KKT conditions are necessary (but not always sufficient) conditions for a point to be optimal in a constrained optimization problem. They involve the gradient of the Lagrangian, constraint satisfaction, and complementary slackness for inequality constraints.
      - question: What is linear least squares and how can it be solved numerically?
        answer: Linear least squares involves finding the value of x that minimizes the squared error between Ax and b. It can be solved numerically using gradient descent or Newton's method.

  # chapter 5
  - chapter: 5
    questions:
      - question: What is a machine learning algorithm?
        answer: A machine learning algorithm is an algorithm that improves its performance on a task by gaining experience from data.
      - question: What are some common machine learning tasks?
        answer: Some common tasks include classification, regression, transcription, machine translation, structured output, anomaly detection, synthesis and sampling, imputation of missing values, denoising, and density estimation.
      - question: What are the key components of a machine learning algorithm?
        answer: Key components include a dataset, a cost function, an optimization procedure, and a model.
      - question: What is generalization error and how does it differ from training error?
        answer: Generalization error is the expected error of a model on new, unseen data, while training error is the error on the data used to train the model.
      - question: What are underfitting and overfitting and how can they be controlled?
        answer: Underfitting occurs when a model is not complex enough to fit the training data well. Overfitting occurs when a model is too complex and learns specific patterns in the training data that do not generalize to new data. Model capacity can be controlled using hyperparameters and regularization techniques.
      - question: What is the no free lunch theorem and what does it imply for machine learning research?
        answer: The no free lunch theorem states that, averaged over all possible data-generating distributions, all machine learning algorithms have the same error rate. This implies that there is no single best algorithm and that researchers should focus on designing algorithms that perform well on specific tasks and data distributions.
      - question: What is regularization and how does it help prevent overfitting?
        answer: Regularization refers to modifications made to a learning algorithm to reduce its generalization error without affecting its training error. This can be achieved by adding penalty terms to the cost function, such as weight decay.
      - question: What are hyperparameters and how are they set?
        answer: Hyperparameters are settings of a learning algorithm that are not adapted by the algorithm itself. They are usually set using a validation set of data that is separate from the training data.
      - question: What is cross-validation and how is it used to estimate generalization error?
        answer: Cross-validation is a technique for estimating generalization error by repeatedly training and testing a model on different subsets of the data. It is used when the dataset is too small for a simple train/test split to provide reliable estimates.
      - question: What are bias and variance in the context of estimators?
        answer: Bias measures the expected deviation of an estimator from the true value. Variance measures the expected deviation of an estimator from its own expected value.
      - question: What is consistency and how does it relate to bias and variance?
        answer: Consistency means that an estimator converges to the true value as the number of data points increases. Consistency implies that the bias of the estimator diminishes as the number of data points grows, but the reverse is not true.
      - question: What is maximum likelihood estimation (MLE) and what are its properties?
        answer: MLE is a principle for deriving estimators by finding the parameter values that maximize the likelihood of the observed data. MLE estimators are often consistent and statistically efficient, meaning they converge to the true value and have low mean squared error.
      - question: What is Bayesian statistics and how does it differ from frequentist statistics?
        answer: Bayesian statistics treats the true parameter value as a random variable and uses a prior distribution to express beliefs about the parameter before observing data. It then uses Bayes' rule to update the prior based on the data, resulting in a posterior distribution.
      - question: What is maximum a posteriori (MAP) estimation and how does it relate to Bayesian inference?
        answer: MAP estimation chooses the parameter value that maximizes the posterior probability distribution. It can be seen as a simplified version of Bayesian inference that provides a single point estimate.
      - question: What is stochastic gradient descent (SGD) and why is it important for deep learning?
        answer: SGD is an optimization algorithm that uses small batches of data to estimate the gradient of the cost function and updates the model parameters iteratively. It is efficient for training large models on large datasets and is widely used in deep learning.
      - question: What is the curse of dimensionality and how does it affect machine learning algorithms?
        answer: The curse of dimensionality refers to the challenges posed by high-dimensional data, such as the exponential growth in the number of possible configurations and the difficulty of generalizing from a limited number of training examples.
      - question: What is the smoothness prior and why is it often insufficient for complex AI tasks?
        answer: The smoothness prior assumes that the function being learned should not change significantly over small regions. While effective for smooth functions in low dimensions, it becomes inadequate for complex functions in high dimensions, leading to overfitting.
      - question: What is manifold learning and how does it address the curse of dimensionality?
        answer: Manifold learning assumes that high-dimensional data lies on low-dimensional manifolds in the input space. By representing the data in terms of coordinates on these manifolds, it becomes possible to learn complex functions with fewer examples and better generalization.

  # chapter 6
  - chapter: 6
    questions:
      - question: What is a deep feedforward network (multilayer perceptron)?
        answer: A deep feedforward network is a type of neural network where information flows in one direction, from input to output, without feedback loops. It consists of multiple layers of interconnected units, with hidden layers performing nonlinear transformations on the input data.
      - question: What is the role of activation functions in deep feedforward networks?
        answer: Activation functions introduce nonlinearity into the network, allowing it to learn complex, non-linear relationships between inputs and outputs. Common activation functions include the rectified linear unit (ReLU), sigmoid, and hyperbolic tangent (tanh).
      - question: What is the universal approximation theorem?
        answer: The universal approximation theorem states that a feedforward network with a single hidden layer and a sufficiently large number of units can approximate any continuous function with arbitrary accuracy.
      - question: What are the advantages of deeper networks?
        answer: Deeper networks can often represent complex functions more efficiently with fewer units and parameters compared to shallower networks. They also tend to generalize better to unseen data.
      - question: What is back-propagation?
        answer: Back-propagation is an algorithm used to compute the gradient of a loss function with respect to the parameters of a neural network. It does so by recursively applying the chain rule of calculus, propagating information backward through the network.
      - question: How does back-propagation work?
        answer: Back-propagation works by constructing a computational graph representing the network and its loss function. It then traverses the graph backwards from the output node, computing the gradient of each node with respect to the output using the chain rule and Jacobian matrices.
      - question: What are some common output units in deep feedforward networks?
        answer: Common output units include linear units for Gaussian output distributions, sigmoid units for Bernoulli distributions, and softmax units for multinoulli distributions.
      - question: What are some common hidden units in deep feedforward networks?
        answer: Common hidden units include rectified linear units (ReLUs), maxout units, logistic sigmoid units, hyperbolic tangent (tanh) units, and radial basis function (RBF) units.
      - question: What are some architectural considerations for deep feedforward networks?
        answer: Architectural considerations include the depth of the network (number of layers), the width of each layer (number of units per layer), the type of connections between layers (fully connected or sparse), and the use of skip connections.
      - question: What are some historical milestones in the development of deep feedforward networks?
        answer: Key milestones include the invention of the perceptron, the development of the back-propagation algorithm, the shift from mean squared error to cross-entropy losses, and the adoption of rectified linear units as the default activation function.

  # chapter 7
  - chapter: 7
    questions:
      - question: What is regularization in machine learning?
        answer: Regularization is any modification made to a learning algorithm that aims to reduce its generalization error (error on unseen data) without affecting its training error (error on the training data).
      - question: What are some common regularization techniques for deep learning models?
        answer: Common regularization techniques include parameter norm penalties (L1, L2), dataset augmentation, noise robustness, early stopping, parameter tying and sharing, sparse representations, bagging and other ensemble methods, dropout, and adversarial training.
      - question: How do parameter norm penalties work?
        answer: Parameter norm penalties add a term to the loss function that penalizes large parameter values, encouraging the model to find solutions with smaller weights. Common penalties include L1 and L2 norms.
      - question: What is the difference between L1 and L2 regularization?
        answer: L1 regularization encourages sparsity, causing many parameters to become zero. L2 regularization shrinks the magnitude of parameters but does not necessarily make them zero.
      - question: How does dataset augmentation help with regularization?
        answer: Dataset augmentation creates new synthetic training examples by applying transformations to existing examples, increasing the training data and improving the model's robustness to variations in the input.
      - question: What is early stopping and how does it work?
        answer: Early stopping monitors the performance of a model on a validation set during training and stops the training process when performance on the validation set starts to degrade, preventing overfitting.
      - question: How does parameter sharing work and what is its purpose?
        answer: Parameter sharing forces certain parameters in a model to be equal, reducing the number of parameters and improving generalization by pooling data across tasks or parts of the model.
      - question: What is dropout and how does it work?
        answer: Dropout is a technique that randomly drops out units (neurons) during training, effectively creating an ensemble of sub-networks. This prevents overfitting by encouraging hidden units to learn more robust features.
      - question: What is adversarial training and how does it help with regularization?
        answer: Adversarial training involves finding adversarial examples, which are input points that are slightly modified to cause a model to make incorrect predictions. The model is then trained to correctly classify these adversarial examples, improving its robustness to small perturbations and reducing the gap between training and test error.
      - question: What is manifold learning and how is it related to regularization?
        answer: Manifold learning assumes that high-dimensional data lies on low-dimensional manifolds in the input space. By learning the manifold structure, regularization techniques like tangent distance and tangent propagation can improve generalization by encouraging models to be locally invariant to variations along the manifold.
      - question: What are some benefits of using regularization techniques in deep learning?
        answer: Benefits include improving generalization, preventing overfitting, reducing the number of parameters, increasing the robustness of models, and making it possible to train larger models with limited data.

  # chapter 8
  - chapter: 8
    questions:
      - question: What are the key differences between optimization in general and optimization for training deep models?
        answer: Optimization for deep learning differs from general optimization because it often involves indirect optimization of a performance measure through a surrogate loss function, takes advantage of the structure of machine learning objective functions, and typically uses minibatches of data to estimate gradients.
      - question: What are the main challenges in optimizing deep neural networks?
        answer: Challenges include ill-conditioning of the Hessian matrix, local minima, plateaus and saddle points, cliffs and exploding gradients, long-term dependencies, and inexact gradients.
      - question: What is stochastic gradient descent (SGD) and how does it work?
        answer: SGD is a first-order optimization algorithm that uses minibatches of data to estimate the gradient and updates parameters iteratively in the direction of the negative gradient.
      - question: What are the advantages and disadvantages of SGD?
        answer: SGD is computationally efficient for large datasets, but it can be slow to converge and is sensitive to the choice of learning rate.
      - question: What is momentum and how does it help with optimization?
        answer: Momentum accelerates learning by accumulating an exponentially decaying moving average of past gradients, allowing the algorithm to escape shallow local minima and navigate regions with high curvature.
      - question: What is Nesterov momentum and how does it differ from standard momentum?
        answer: Nesterov momentum evaluates the gradient at a point slightly ahead of the current position, incorporating a correction factor that can lead to faster convergence.
      - question: What are some common parameter initialization strategies for deep models?
        answer: Common strategies include random initialization from a Gaussian or uniform distribution, normalized initialization, orthogonal initialization, and sparse initialization.
      - question: What are adaptive learning rate algorithms and how do they work?
        answer: Adaptive learning rate algorithms adjust the learning rate for each parameter individually during training, typically scaling them based on the magnitude of past gradients. Examples include AdaGrad, RMSProp, and Adam.
      - question: What is Newton's method and how does it utilize second-order information?
        answer: Newton's method is a second-order optimization algorithm that uses the Hessian matrix to approximate the cost function as a quadratic and jumps directly to the minimum of the approximation.
      - question: What are the main challenges in applying Newton's method to deep learning?
        answer: Challenges include the computational cost of computing the Hessian and its inverse, as well as the presence of saddle points and other nonconvex structures.
      - question: What are conjugate gradient methods and how do they overcome the limitations of Newton's method?
        answer: Conjugate gradient methods aim to avoid computing the inverse Hessian by iteratively descending conjugate directions, which are chosen to avoid undoing progress made in previous directions.
      - question: What is the BFGS algorithm and how does it approximate Newton's method?
        answer: BFGS is a quasi-Newton method that iteratively refines an approximation of the inverse Hessian using low-rank updates, allowing it to take advantage of second-order information without the computational burden of computing the full Hessian.
      - question: What is batch normalization and how does it improve optimization?
        answer: Batch normalization is a technique that normalizes the mean and variance of hidden unit activations during training, making the learning process more stable and robust to the choice of initial parameters and learning rates.
      - question: What is coordinate descent and how is it used for optimization?
        answer: Coordinate descent optimizes a function by iteratively minimizing it with respect to a single variable or a group of variables at a time. It is effective for problems where variables can be separated into groups with relatively independent effects.
      - question: What is Polyak averaging and how does it help with optimization?
        answer: Polyak averaging averages the parameters visited by an optimization algorithm over time, potentially smoothing out oscillations and improving the final solution.
      - question: What is supervised pretraining and how does it aid optimization?
        answer: Supervised pretraining involves training simpler models on simpler tasks to initialize a more complex model, providing better starting parameters and guiding the optimization process.
      - question: What are some strategies for designing deep models to improve optimization?
        answer: Strategies include using activation functions with linear behavior, adding skip connections between layers, incorporating auxiliary heads, and applying continuation methods and curriculum learning.
      - question: What are continuation methods and how are they used for optimization?
        answer: Continuation methods gradually transform a complex objective function into a series of simpler, easier-to-optimize functions, guiding the optimization algorithm towards a good solution.
      - question: What is curriculum learning and how does it relate to continuation methods?
        answer: Curriculum learning involves presenting training examples in a carefully planned order, starting with simpler examples and progressing to more complex ones. This can be viewed as a continuation method that simplifies the early stages of learning.

  # chapter 9
  - chapter: 9
    questions:
      - question: What is a convolutional neural network (CNN)?
        answer: A CNN is a type of neural network that uses convolution in place of general matrix multiplication in at least one of its layers. It is specialized for processing data with a grid-like topology, such as images and time series.
      - question: What is convolution?
        answer: Convolution is a mathematical operation that combines two functions to produce a third function. In the context of CNNs, it involves applying a kernel (a small filter) to the input data, sliding it across the input and computing a weighted sum of the overlapping values.
      - question: What are the advantages of using convolution in neural networks?
        answer: Convolution offers advantages such as sparse interactions, parameter sharing, and equivariant representations, making it more efficient and effective for processing grid-structured data.
      - question: What is pooling in CNNs and what is its purpose?
        answer: Pooling is a technique used in CNNs to downsample feature maps by replacing a neighborhood of values with a summary statistic, such as the maximum or average value. It helps to introduce invariance to small translations, making the model more robust to variations in input position.
      - question: What are some variants of the convolution operation used in CNNs?
        answer: Variants include multichannel convolution, strided convolution, zero padding, locally connected layers, tiled convolution, and transposed convolution.
      - question: How can convolutional networks handle inputs of varying sizes?
        answer: Convolution can naturally process inputs with different spatial extents, as the operation is applied a variable number of times depending on the input size. Pooling layers can be used to adjust the output size to a fixed value.
      - question: How are convolutional networks inspired by neuroscience?
        answer: CNNs draw inspiration from the structure and function of the mammalian visual system, particularly the primary visual cortex (V1). Convolutional layers mimic the behavior of simple cells, which are receptive to specific features in localized regions of the input. Pooling layers resemble complex cells, which are invariant to small shifts in feature positions.
      - question: What is the role of convolutional networks in the history of deep learning?
        answer: CNNs were some of the first successful deep models, demonstrating the viability of deep architectures for complex tasks. They have been crucial in driving the modern deep learning renaissance, particularly in computer vision applications.

  # chapter 10
  - chapter: 10
    questions:
      - question: What are recurrent neural networks (RNNs)?
        answer: RNNs are a family of neural networks designed for processing sequential data, where the output at a given time step is influenced by the outputs of previous time steps. They achieve this through recurrent connections, allowing information to flow through time.
      - question: What is the main advantage of RNNs over feedforward networks for processing sequences?
        answer: RNNs share parameters across different time steps, allowing them to generalize to sequences of varying lengths and learn patterns that occur at different positions within a sequence.
      - question: What is the concept of unfolding a computational graph for RNNs?
        answer: Unfolding involves converting a recurrent computation into a directed acyclic graph with a repetitive structure, where each node represents the state at a particular time step. This allows for easier visualization and analysis of information flow.
      - question: What are some common RNN architectures?
        answer: Common architectures include RNNs with recurrent connections between hidden units, RNNs with connections from the output at one time step to the hidden units at the next, and RNNs with a single output at the end of the sequence.
      - question: What is teacher forcing and how is it used to train RNNs?
        answer: Teacher forcing is a training technique used in RNNs with output-to-hidden connections. It involves feeding the correct target output at each time step as input to the model, avoiding the need for back-propagation through time and allowing for parallelization during training.
      - question: What is back-propagation through time (BPTT)?
        answer: BPTT is the algorithm used to compute gradients for RNNs. It applies the general back-propagation algorithm to the unfolded computational graph, propagating gradients backward through time.
      - question: What are bidirectional RNNs and what is their purpose?
        answer: Bidirectional RNNs combine two RNNs, one moving forward and one moving backward through time, allowing the output at each time step to benefit from information from both the past and the future.
      - question: What is an encoder-decoder or sequence-to-sequence architecture?
        answer: It is an RNN architecture that maps an input sequence to an output sequence, often of varying lengths. It consists of an encoder RNN that summarizes the input sequence into a context vector and a decoder RNN that generates the output sequence based on the context.
      - question: What is the challenge of long-term dependencies in RNNs?
        answer: Long-term dependencies arise when a model needs to learn relationships between events that are far apart in time. The vanishing and exploding gradient problem can make it difficult to capture these relationships.
      - question: What are echo state networks (ESNs)?
        answer: ESNs are a type of RNN where the recurrent weights are fixed, and only the output weights are learned. This simplifies training by reducing the optimization problem to a convex one.
      - question: How do leaky units and skip connections help with long-term dependencies?
        answer: Leaky units introduce linear self-connections that allow information to be accumulated over longer durations. Skip connections directly connect units across multiple time steps, providing a faster pathway for information flow.
      - question: What are gated RNNs and how do they work?
        answer: Gated RNNs, such as LSTMs and GRUs, introduce gating units that control the flow of information through time, allowing the network to dynamically adjust the time scale and forget irrelevant information.
      - question: What is the purpose of explicit memory in neural networks?
        answer: Explicit memory allows neural networks to store and retrieve specific facts, enabling them to perform tasks requiring reasoning and manipulation of knowledge, similar to human working memory.
      - question: What are memory networks and neural Turing machines?
        answer: Memory networks include a set of memory cells that can be accessed via an addressing mechanism, enabling them to store and retrieve information. Neural Turing machines are a type of memory network that learn to read and write to memory cells without explicit supervision.
      - question: How does the attention mechanism help with processing sequences?
        answer: Attention mechanisms allow a network to focus on specific parts of the input sequence that are most relevant for the current task, enabling it to process sequences of varying lengths and capture long-range dependencies.

  # chapter 11
  - chapter: 11
    questions:
      - question: What are some important practical considerations for applying deep learning?
        answer: Practical considerations include defining clear goals and performance metrics, establishing a baseline system, gathering more data if necessary, tuning hyperparameters, debugging and identifying bottlenecks, and iteratively improving the system.
      - question: What are the key steps in a practical deep learning design process?
        answer: Key steps include defining goals and performance metrics, establishing a working end-to-end pipeline, instrumenting the system, and iteratively making incremental changes based on feedback.
      - question: How do you choose the right performance metric for your deep learning task?
        answer: The metric should be tailored to the specific problem you are solving. Common metrics include accuracy, error rate, precision, recall, F-score, coverage, and task-specific metrics.
      - question: What are some reasonable baseline models to start with for different deep learning tasks?
        answer: For fixed-size vector inputs, use a feedforward network with fully connected layers and ReLU activation. For grid-structured data (images), use a convolutional network with ReLUs. For sequences, use a gated recurrent network (LSTM or GRU). Include early stopping and dropout for regularization.
      - question: How do you decide whether to gather more data or improve the learning algorithm?
        answer: If training error is high, focus on improving the model's capacity or the quality of the training data. If test error is significantly higher than training error, gathering more data is usually the most effective solution. If gathering more data is not feasible, focus on improving regularization techniques.
      - question: What are the two main approaches to hyperparameter optimization?
        answer: The two main approaches are manual tuning and automatic algorithms. Manual tuning requires understanding the relationship between hyperparameters and model performance, while automatic algorithms (like grid search, random search, and Bayesian optimization) can find good values but are often more computationally expensive.
      - question: How do you debug a deep learning system?
        answer: Debugging strategies include visualizing the model's behavior, analyzing worst mistakes, reasoning about software based on training and test errors, fitting a tiny dataset, comparing back-propagated derivatives to numerical derivatives, and monitoring histograms of activations and gradients.
      - question: What is the importance of establishing a working end-to-end pipeline early in the design process?
        answer: A working pipeline allows you to quickly measure the performance of your system and identify areas for improvement, enabling faster iteration and development.
      - question: What are some general guidelines for tuning hyperparameters?
        answer: Tune hyperparameters by considering their effect on model capacity. Use a decaying learning rate and include early stopping and dropout for regularization. Experiment with hyperparameter values on a logarithmic scale.
      - question: What are some alternative hyperparameter optimization methods beyond grid search?
        answer: Alternatives include random search, which is more efficient and practical for a large number of hyperparameters, and model-based optimization, which uses Bayesian regression to guide the search process.

  # chapter 12
  - chapter: 12
    questions:
      - question: What are the key factors behind the success of deep learning in various applications?
        answer: Deep learning's success is driven by the availability of large datasets, the development of more powerful hardware (GPUs and distributed computing), and advancements in algorithms (including improved optimization, regularization, and architectures).
      - question: What are some common preprocessing techniques used in computer vision?
        answer: Common preprocessing techniques include standardizing pixel values, resizing images, and dataset augmentation (e.g., translation, rotation, color perturbation).
      - question: What is contrast normalization and why is it important for image processing?
        answer: Contrast normalization aims to make images have consistent contrast levels, reducing the need for the model to handle varying contrast levels. It can be global (normalizing across the entire image) or local (normalizing within small windows).
      - question: What is the role of deep learning in speech recognition?
        answer: Deep learning has revolutionized speech recognition by replacing traditional GMM-HMM systems with deep neural networks for modeling the association between acoustic features and phonemes or subphonemic states.
      - question: What are some key innovations in deep learning-based speech recognition?
        answer: Innovations include the use of convolutional networks for processing spectrograms, end-to-end systems that eliminate the need for HMMs, and models that learn to align acoustic and phonetic information.
      - question: How does deep learning contribute to natural language processing (NLP)?
        answer: Deep learning has enabled the development of neural language models that learn distributed representations (embeddings) for words, capturing semantic information and allowing for generalization across similar words and contexts.
      - question: What are some challenges in training neural language models with large vocabularies?
        answer: Challenges include the high computational cost of computing the output distribution over a large vocabulary, the need to handle sparse outputs, and the difficulty of optimizing the softmax function.
      - question: What are some strategies for addressing the computational challenges of large vocabularies?
        answer: Strategies include using shortlists of frequent words, hierarchical softmax, importance sampling, noise-contrastive estimation, and ranking loss.
      - question: How can deep learning be used for recommender systems?
        answer: Deep learning can learn user and item embeddings, which can be used for collaborative filtering or content-based recommendations. It can also model the exploration-exploitation trade-off inherent in recommender systems.
      - question: How is deep learning being used for knowledge representation and reasoning?
        answer: Deep learning is used to learn embeddings for entities and relations, enabling models to capture knowledge from knowledge bases and perform tasks like link prediction and word-sense disambiguation.
      - question: What are the challenges and opportunities in applying deep learning to question answering?
        answer: Challenges include the need for robust memory mechanisms to store and retrieve facts, as well as the ability to reason about relationships between facts. Opportunities include building general question-answering systems that can understand and respond to natural language queries.

  # chapter 13
  - chapter: 13
    questions:
      - question: What are linear factor models?
        answer: Linear factor models are probabilistic models that explain observed data as a linear combination of latent factors plus noise. They typically assume independent latent factors and Gaussian noise.
      - question: What are probabilistic PCA and factor analysis, and how do they differ?
        answer: Probabilistic PCA and factor analysis are special cases of linear factor models. Factor analysis assumes a unit variance Gaussian prior over latent factors and conditionally independent observed variables with a diagonal covariance matrix. Probabilistic PCA assumes equal conditional variances for the observed variables, resulting in a simpler covariance structure for the observed data.
      - question: What is independent component analysis (ICA)?
        answer: ICA is a technique for separating a mixed signal into its independent components. It aims to find a linear transformation that makes the latent factors as independent as possible.
      - question: What are the key assumptions and requirements for ICA?
        answer: ICA assumes non-Gaussian independent latent factors and typically uses a deterministic decoder. It is often used for signal separation tasks.
      - question: What is slow feature analysis (SFA)?
        answer: SFA is a linear factor model that learns features that change slowly over time. It is motivated by the slowness principle, which states that important features in a scene tend to change slowly compared to individual measurements.
      - question: What is sparse coding and how does it work?
        answer: Sparse coding is a linear factor model that learns a dictionary of features and infers a sparse code representation for each data point. It assumes a prior over latent factors that encourages sparsity (many zero or near-zero values).
      - question: How can PCA be interpreted as a manifold learning technique?
        answer: Probabilistic PCA can be seen as defining a low-dimensional manifold embedded in a higher-dimensional space, where the data concentrates around a thin "pancake" shaped region of high probability.
      - question: What are some advantages and disadvantages of linear factor models?
        answer: Advantages include their simplicity, analytical tractability, and ability to discover explanatory factors. Disadvantages include their limited capacity for modeling complex data distributions and their tendency to produce poor samples.
      - question: What are some examples of applications where linear factor models are useful?
        answer: Applications include dimensionality reduction, feature learning, signal separation (ICA), and discovering slow features (SFA).

  # chapter 14
  - chapter: 14
    questions:
      - question: What is an autoencoder?
        answer: An autoencoder is a neural network trained to reconstruct its input at the output. It learns a compressed representation (code) of the input in a hidden layer.
      - question: What is the difference between undercomplete, overcomplete, and regularized autoencoders?
        answer: Undercomplete autoencoders have a code dimension smaller than the input dimension, forcing them to learn salient features. Overcomplete autoencoders have a code dimension larger than the input, potentially leading to trivial solutions. Regularized autoencoders add constraints or penalties to the loss function to encourage desired properties in the code, such as sparsity or robustness to noise.
      - question: What are sparse autoencoders and how do they learn useful features?
        answer: Sparse autoencoders add a sparsity penalty to the loss function, encouraging the hidden code to have many zero or near-zero values. This forces the encoder to learn features that capture unique statistical aspects of the data.
      - question: What are denoising autoencoders and what is their training procedure?
        answer: Denoising autoencoders are trained to reconstruct the original, clean data point from a noisy version of the input. This forces the encoder and decoder to learn the structure of the data distribution.
      - question: What is a contractive autoencoder (CAE)?
        answer: A CAE adds a penalty to the loss function that encourages the derivatives of the encoder to be small. This promotes local constancy and helps to learn the manifold structure of the data.
      - question: What are the advantages of using deep autoencoders?
        answer: Deep autoencoders can represent complex mappings from input to code more efficiently and can learn more powerful, multi-level representations of the data.
      - question: How can autoencoders be made stochastic?
        answer: Stochastic autoencoders generalize the encoder and decoder functions to probability distributions (*p*encoder and *p*decoder). This allows for more flexible representations and can be used for generative modeling.
      - question: How do autoencoders relate to manifold learning?
        answer: Autoencoders implicitly learn the manifold structure of the data by learning a representation that is sensitive to variations along the manifold and insensitive to variations orthogonal to it.
      - question: What is predictive sparse decomposition (PSD)?
        answer: PSD combines aspects of sparse coding and parametric autoencoders, learning an encoder that predicts the output of iterative inference. It is a powerful method for unsupervised feature learning.
      - question: What are some applications of autoencoders?
        answer: Applications include dimensionality reduction, information retrieval (semantic hashing), and pretraining features for other tasks, such as classification.

  # chapter 15
  - chapter: 15
    questions:
      - question: What is representation learning?
        answer: Representation learning is the task of learning a new representation of the input data that is more informative and useful for a subsequent learning task.
      - question: How can representation learning be used for unsupervised and semi-supervised learning?
        answer: Unsupervised representation learning can learn useful features from unlabeled data, which can then be used to initialize or regularize supervised models, improving performance on the supervised task.
      - question: What is greedy layer-wise unsupervised pretraining?
        answer: Greedy layer-wise unsupervised pretraining involves training a deep model layer by layer, using an unsupervised representation learning algorithm for each layer, and then optionally fine-tuning the entire model with a supervised learning objective.
      - question: When and why does unsupervised pretraining work?
        answer: Unsupervised pretraining can be effective when the initial representation is poor, the number of labeled examples is limited, or the task is complex and involves regularities in the data distribution.
      - question: What are some key benefits of transfer learning and domain adaptation?
        answer: Transfer learning allows knowledge learned in one setting to be transferred to another, often related, setting, improving generalization. Domain adaptation addresses the situation where the task is the same but the input distribution differs across domains.
      - question: What is the role of disentangling causal factors in representation learning?
        answer: Disentangling causal factors aims to learn a representation where features correspond to underlying causes of the observed data, making it easier to model and predict target variables that are related to those causes.
      - question: What are the advantages of distributed representations?
        answer: Distributed representations allow for the encoding of a large number of concepts with a relatively small number of features, enabling generalization and capturing complex relationships between variables.
      - question: How can depth in deep models lead to exponential gains in representational power?
        answer: Deep models can represent complex functions more efficiently with fewer parameters than shallow models, offering significant advantages in terms of statistical efficiency and generalization.
      - question: What are some generic clues or prior beliefs that guide representation learning algorithms?
        answer: Clues include smoothness, linearity, multiple explanatory factors, causal factors, depth, shared factors across tasks, manifolds, natural clustering, temporal and spatial coherence, sparsity, and simplicity of factor dependencies.

  # chapter 16
  - chapter: 16
    questions:
      - question: What are structured probabilistic models, and why are they important?
        answer: Structured probabilistic models, also known as graphical models, represent probability distributions using graphs. The graph encodes dependencies between variables, allowing for more efficient representation, learning, and inference compared to unstructured models.
      - question: What are directed graphical models (belief networks)?
        answer: Directed graphical models use directed edges to represent dependencies, where an arrow from node A to node B indicates that the distribution of B is conditioned on the value of A. They are defined by local conditional probability distributions.
      - question: What are undirected graphical models (Markov random fields)?
        answer: Undirected graphical models use undirected edges to represent dependencies. Each clique in the graph is associated with a factor (clique potential), which measures the affinity of variables in the clique for being in certain joint states.
      - question: What is the partition function in undirected models?
        answer: The partition function (Z) is a normalizing constant used to convert an unnormalized probability distribution into a valid probability distribution. It is often intractable to compute exactly, requiring approximations.
      - question: What are energy-based models (EBMs)?
        answer: EBMs are undirected models where the probability distribution is defined in terms of an energy function, with higher energy corresponding to lower probability.
      - question: What are separation and d-separation in graphical models?
        answer: Separation and d-separation are concepts for identifying conditional independences implied by the graph structure. They involve examining paths between variables, with active paths indicating dependence and inactive paths indicating independence.
      - question: How can you convert between directed and undirected graphical models?
        answer: Directed models can be converted to undirected models by moralization, which adds edges to connect parents of a common child. Undirected models can be converted to directed models by triangulating the graph (adding chords to loops) and assigning edge directions.
      - question: What are factor graphs?
        answer: Factor graphs are a type of undirected graphical model that explicitly represents the scope of each factor, making the model structure unambiguous.
      - question: What is ancestral sampling and how is it used for sampling from directed models?
        answer: Ancestral sampling is an efficient sampling method for directed models. It involves sorting the variables in a topological order and sampling them one by one based on the conditional probability distributions defined in the model.
      - question: What are the advantages of structured probabilistic models?
        answer: Advantages include efficient representation of complex distributions, reduced computational cost for learning and inference, and clear separation of knowledge representation from learning and inference.
      - question: How can latent variables help to capture dependencies between observed variables?
        answer: Latent variables allow for indirect dependencies between observed variables by introducing direct interactions between the observed variables and the latent variables.
      - question: What are the key differences between the deep learning approach and the traditional graphical models approach to structured probabilistic models?
        answer: Deep learning typically uses models with distributed representations, dense connectivity, large numbers of latent variables, and efficient algorithms for approximate inference (e.g., Gibbs sampling, variational inference). Traditional graphical models often focus on sparse connectivity, exact inference, and interpretable latent variables.
      - question: What is a restricted Boltzmann machine (RBM) and how does it exemplify the deep learning approach?
        answer: An RBM is a simple energy-based model with a single layer of latent variables. It demonstrates the use of distributed representations, efficient matrix-based interactions between layers, and a focus on efficient Gibbs sampling for training.

  # chapter 17
  - chapter: 17
    questions:
      - question: What are Monte Carlo methods, and how do they differ from deterministic algorithms?
        answer: Monte Carlo methods are randomized algorithms that approximate a desired quantity by drawing samples from a probability distribution and using those samples to form an estimate. Unlike deterministic algorithms, which provide an exact solution, Monte Carlo methods introduce a random amount of error that can be reduced by using more samples.
      - question: Why are Monte Carlo methods useful for machine learning?
        answer: Many machine learning problems involve intractable sums, integrals, or sampling tasks. Monte Carlo methods provide a way to approximate these quantities efficiently, even when exact computation is infeasible.
      - question: What is importance sampling?
        answer: Importance sampling is a technique for estimating an expectation under one distribution by drawing samples from another distribution and weighting them appropriately. This can be more efficient than sampling directly from the target distribution.
      - question: How does importance sampling work?
        answer: Importance sampling works by drawing samples from a proposal distribution (q) and weighting those samples by the ratio of the target distribution (p) to the proposal distribution at each sample point. This allows for estimating expectations even when direct sampling from the target distribution is difficult.
      - question: What are Markov chain Monte Carlo (MCMC) methods?
        answer: MCMC methods use Markov chains to approximate a probability distribution by repeatedly updating a random state based on a transition distribution. Eventually, the state of the Markov chain converges to a stationary distribution, which approximates the target distribution.
      - question: How does Gibbs sampling work?
        answer: Gibbs sampling is a specific MCMC method that updates a variable by sampling from its conditional distribution, given the values of its neighbors in the undirected graph.
      - question: What is the challenge of slow mixing in MCMC methods?
        answer: Slow mixing refers to the situation where successive samples from a Markov chain are highly correlated and do not explore the target distribution efficiently. This can be a problem when there are multiple modes in the distribution.
      - question: What is tempering, and how can it help with mixing?
        answer: Tempering involves temporarily sampling from a higher-temperature version of the target distribution, where the modes are less pronounced. This can make it easier for the Markov chain to mix between modes and then return to the original distribution.
      - question: How can depth in deep models help with mixing?
        answer: Deeper models can learn more complex representations of the data, leading to a more uniform and less multimodal distribution in the latent space. This can improve mixing for Markov chains sampling from the model distribution.
      - question: What are some limitations of Monte Carlo methods?
        answer: Limitations include the need to burn in the Markov chain to reach equilibrium, the correlation between successive samples, and the difficulty in determining how long it takes for a chain to mix.

  # chapter 18
  - chapter: 18
    questions:
      - question: What is the partition function in undirected probabilistic models?
        answer: The partition function (Z) is a normalizing constant used to convert an unnormalized probability distribution into a valid probability distribution. It is often intractable to compute, especially for complex models.
      - question: How does the partition function affect the gradient of the log-likelihood?
        answer: The gradient of the log-likelihood includes a term corresponding to the gradient of the partition function, making it difficult to compute for models with intractable partition functions.
      - question: What are the positive and negative phases of learning in undirected models?
        answer: The positive phase involves increasing the unnormalized probability of training examples, while the negative phase involves decreasing the partition function by pushing down on the unnormalized probability of samples drawn from the model distribution.
      - question: What is contrastive divergence (CD)?
        answer: CD is an approximation to the gradient of the log-likelihood that uses a short Markov chain initialized from the data distribution to estimate the negative phase. It is computationally efficient but can suffer from bias and the formation of spurious modes.
      - question: What is stochastic maximum likelihood (SML) or persistent contrastive divergence (PCD)?
        answer: SML/PCD is an alternative to CD that initializes the Markov chain at each gradient step with samples from the previous step. This reduces the need for burn-in and allows for efficient training of deeper models.
      - question: What is pseudolikelihood?
        answer: Pseudolikelihood is a method for training undirected models without explicitly computing the partition function. It involves maximizing the conditional probabilities of individual variables given all other variables, avoiding the need for marginalization.
      - question: What is score matching?
        answer: Score matching is a method for training models without estimating the partition function. It encourages the model to have the same score (gradient of the log density) as the data distribution at every training point.
      - question: What is denoising score matching?
        answer: Denoising score matching is a regularized version of score matching that uses a corruption process to smooth the distribution, making it more robust to noise and avoiding overfitting.
      - question: What is noise-contrastive estimation (NCE)?
        answer: NCE is a method that reduces unsupervised learning to a supervised classification problem by introducing a noise distribution. It aims to learn a model that can distinguish data from noise.
      - question: How can importance sampling be used to estimate the partition function?
        answer: Importance sampling draws samples from a proposal distribution (p0) and weights them by the ratio of the target distribution (p1) to the proposal distribution. This can be used to estimate the ratio of the partition functions of two distributions.
      - question: What are annealed importance sampling (AIS) and bridge sampling?
        answer: AIS and bridge sampling address the challenge of estimating partition functions for complex distributions by introducing intermediate distributions that bridge the gap between the proposal distribution and the target distribution. AIS chains a series of intermediate distributions, while bridge sampling uses a single bridge distribution.
      - question: What are some challenges in estimating the partition function?
        answer: Challenges include finding a good proposal distribution that is close enough to the target distribution to reduce variance, and the computational cost of sampling and evaluating the intermediate distributions.

  # chapter 19
  - chapter: 19
    questions:
      - question: What is approximate inference, and why is it necessary?
        answer: Approximate inference is a technique used to estimate intractable quantities in probabilistic models, such as the posterior distribution over latent variables or the partition function. It is necessary because exact inference is often computationally infeasible, especially for complex models with many latent variables.
      - question: What is the evidence lower bound (ELBO)?
        answer: The ELBO is a lower bound on the log-likelihood of the observed data. It is used in variational inference to guide the optimization of an approximate posterior distribution.
      - question: What is the expectation-maximization (EM) algorithm?
        answer: The EM algorithm is a learning algorithm for models with latent variables. It iteratively alternates between an expectation step (E-step) that computes the expected value of the complete data log-likelihood given the current model parameters and a maximization step (M-step) that updates the model parameters to maximize the expected log-likelihood.
      - question: What is MAP inference?
        answer: MAP inference involves finding the most likely value of the latent variables, given the observed variables, rather than computing the entire posterior distribution. It can be seen as a form of approximate inference by restricting the variational distribution to a Dirac delta function.
      - question: How does variational inference work?
        answer: Variational inference approximates the true posterior distribution by finding the closest distribution within a restricted family of distributions, typically by maximizing the ELBO.
      - question: How does variational inference differ for discrete and continuous latent variables?
        answer: For discrete variables, variational inference involves optimizing a finite number of parameters that define the variational distribution. For continuous variables, calculus of variations is used to optimize over a space of functions.
      - question: What is the wake-sleep algorithm?
        answer: The wake-sleep algorithm is a technique for training a generative model and its associated inference network. It uses samples from the model distribution to train the inference network to predict latent variables given observed variables.
      - question: What is learned approximate inference?
        answer: Learned approximate inference involves training a neural network to perform approximate inference in a probabilistic model. This can be more efficient than traditional iterative inference algorithms.
      - question: What are some examples of learned approximate inference methods?
        answer: Examples include wake-sleep, predictive sparse decomposition (PSD), and the variational autoencoder (VAE).
      - question: What are some challenges and limitations of approximate inference?
        answer: Challenges include choosing the right family of approximating distributions, ensuring that the approximation is accurate enough, and understanding the impact of approximations on the learning process.

  # chapter 20
  - chapter: 20
    questions:
      - question: What are deep generative models, and why are they important?
        answer: Deep generative models are probabilistic models that aim to capture the underlying data distribution and allow for tasks like sampling, density estimation, and inference. They are important because they provide a powerful framework for understanding complex data and generating new, realistic samples.
      - question: What are Boltzmann machines?
        answer: Boltzmann machines are undirected graphical models that learn a probability distribution over binary variables based on an energy function. They can be used for both unsupervised learning and generative modeling.
      - question: What are restricted Boltzmann machines (RBMs)?
        answer: RBMs are a type of Boltzmann machine with a bipartite graph structure, where visible units are connected to hidden units but not to each other. This restriction allows for efficient training and sampling using Gibbs sampling.
      - question: What are deep belief networks (DBNs)?
        answer: DBNs are generative models with multiple layers of latent variables. They are trained greedily, layer by layer, using RBMs to initialize the parameters. They are less commonly used than other generative models today.
      - question: What are deep Boltzmann machines (DBMs)?
        answer: DBMs are entirely undirected generative models with multiple layers of latent variables. They are more challenging to train than RBMs, typically requiring greedy layer-wise pretraining, but they can capture more complex interactions between variables.
      - question: What are some techniques for training Boltzmann machines?
        answer: Training techniques for Boltzmann machines with intractable partition functions include contrastive divergence (CD), stochastic maximum likelihood (SML) or persistent contrastive divergence (PCD), and noise-contrastive estimation (NCE).
      - question: How can you model real-valued data with Boltzmann machines?
        answer: Gaussian-Bernoulli RBMs extend the RBM framework to handle real-valued visible units by modeling the conditional distribution of those units as a Gaussian distribution.
      - question: What are some models for handling conditional covariance in real-valued data?
        answer: Models include the mean and covariance RBM (mcRBM), the mean product of Student *t*-distributions (mPoT), and the spike and slab RBM (ssRBM).
      - question: What are convolutional Boltzmann machines?
        answer: Convolutional Boltzmann machines extend the RBM framework to handle grid-structured data like images by using convolution instead of matrix multiplication. They typically incorporate probabilistic max pooling to handle downsampling.
      - question: How can Boltzmann machines be used for structured outputs and sequence modeling?
        answer: Conditional Boltzmann machines can model probability distributions over structured outputs by introducing a conditional distribution over the output variables given the input. This can be applied to tasks like speech synthesis or modeling sequences of skeletal joint angles.
      - question: What is the reparametrization trick for back-propagation through stochastic operations?
        answer: The reparametrization trick rewrites a stochastic operation as a deterministic function with an extra random input (z). This allows for back-propagation through the sampling process and the computation of gradients with respect to the parameters of the distribution.
      - question: How can you back-propagate through discrete stochastic operations?
        answer: For discrete variables, the reparametrization trick is not applicable. The REINFORCE algorithm provides a way to estimate the gradient by correlating the choice of the discrete variable with the corresponding value of the loss function.
      - question: What are generative stochastic networks (GSNs)?
        answer: GSNs are generative models that use a stochastic Markov chain to generate data. They are trained to maximize the reconstruction log-probability of the visible units by back-propagating through the sampling process.
      - question: What are variational autoencoders (VAEs)?
        answer: VAEs are a generative model that uses a neural network encoder to approximate the posterior distribution over latent variables and a neural network decoder to generate samples from the data distribution. They are trained by maximizing a variational lower bound on the log-likelihood.
      - question: What are generative adversarial networks (GANs)?
        answer: GANs are generative models that involve a game between a generator network and a discriminator network. The generator aims to produce samples that fool the discriminator, while the discriminator learns to distinguish between real data and generated samples.
      - question: What are generative moment matching networks?
        answer: Generative moment matching networks train a generator to match the moments (statistical properties) of the generated samples with those of the real data distribution, using a kernel-based measure called the maximum mean discrepancy (MMD).
      - question: What are some techniques for improving sample quality in generative models?
        answer: Techniques include using convolutional generator networks, incorporating adversarial training, and combining generator networks with autoencoders.
      - question: What are some challenges in evaluating generative models?
        answer: Challenges include the difficulty in evaluating the log-likelihood, the need to consider the trade-off between different metrics, and the potential for models to overfit or underfit while producing visually convincing samples.
